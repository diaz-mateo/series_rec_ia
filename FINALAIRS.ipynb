{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86697971-a423-44ed-8642-4d73eb3c0d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import json\n",
    "import time\n",
    "import google.generativeai as genai\n",
    "\n",
    "# Configuraci√≥n b√°sica de logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f2b255d-1362-43ce-b725-e3e6f9cf5e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeriesRecommender:\n",
    "    def __init__(self, text_model: str = \"gemini-pro\", vision_model: str = \"gemini-1.5-flash\", cache_file: str = \"series_recommender_results.json\"):\n",
    "        \"\"\"\n",
    "        Inicializa la instancia, carga la cach√© desde archivo si existe, configura la API y asigna modelos.\n",
    "        \"\"\"\n",
    "        self.text_model = text_model\n",
    "        self.vision_model = vision_model  # Actualizado a \"gemini-1.5-flash\"\n",
    "        self.cache_file = cache_file\n",
    "        self.cache = self.load_cache()\n",
    "        self.user_series = None\n",
    "        \n",
    "        # Configurar la API: se obtiene la API Key desde variable de entorno o se asigna manualmente\n",
    "        self.api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "        if not self.api_key:\n",
    "            self.api_key = \"AIzaSyC7BdE1Pak3i0Vv2VhieFxvkqrDpHSHdCQ\"  # REEMPLAZA con tu API key si no usas variables de entorno\n",
    "        genai.configure(api_key=self.api_key)\n",
    "        logging.info(\"API de Google Gemini configurada correctamente.\")\n",
    "\n",
    "    def load_cache(self) -> dict:\n",
    "        if os.path.exists(self.cache_file):\n",
    "            try:\n",
    "                with open(self.cache_file, \"r\", encoding=\"utf-8\") as f:\n",
    "                    cache_data = json.load(f)\n",
    "                    logging.info(\"Cach√© cargada desde archivo.\")\n",
    "                    return cache_data\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error al cargar cach√©: {e}\")\n",
    "        return {}\n",
    "\n",
    "    def save_cache(self):\n",
    "        try:\n",
    "            with open(self.cache_file, \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump(self.cache, f, ensure_ascii=False, indent=4)\n",
    "            logging.info(\"Cach√© guardada en archivo JSON.\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error al guardar cach√©: {e}\")\n",
    "\n",
    "    def get_user_series(self) -> str:\n",
    "        while True:\n",
    "            series = input(\"Ingrese el nombre de su serie favorita: \").strip()\n",
    "            if series:\n",
    "                logging.info(f\"Serie ingresada: {series}\")\n",
    "                return series\n",
    "            else:\n",
    "                print(\"Entrada vac√≠a. Por favor, ingrese una serie v√°lida.\")\n",
    "\n",
    "    def generate_recommendations(self, series_name: str) -> str:\n",
    "        if series_name in self.cache and \"recommendations\" in self.cache[series_name]:\n",
    "            logging.info(\"Recomendaciones obtenidas desde cach√©.\")\n",
    "            return self.cache[series_name][\"recommendations\"]\n",
    "\n",
    "        prompt = (\n",
    "            f\"Eres un experto en series de televisi√≥n y streaming. \"\n",
    "            f\"Un usuario te dice que su serie favorita es '{series_name}'. \"\n",
    "            \"Recomi√©ndale al menos 5 series similares y explica brevemente por qu√© podr√≠an gustarle.\"\n",
    "        )\n",
    "        try:\n",
    "            model = genai.GenerativeModel(self.text_model)\n",
    "            response = model.generate_content(prompt)\n",
    "            recommendations = response.text if response and response.text else \"No se pudieron generar recomendaciones.\"\n",
    "            logging.info(\"Recomendaciones generadas exitosamente.\")\n",
    "            if series_name not in self.cache:\n",
    "                self.cache[series_name] = {}\n",
    "            self.cache[series_name][\"recommendations\"] = recommendations\n",
    "            return recommendations\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error al generar recomendaciones: {e}\")\n",
    "            return \"Error al generar recomendaciones.\"\n",
    "\n",
    "    def extract_series_names(self, recommendations_text: str) -> str:\n",
    "        prompt = (\n",
    "            \"Extrae solo los nombres de las series mencionadas en el siguiente texto:\\n\"\n",
    "            f\"{recommendations_text}\\n\"\n",
    "            \"Devuelve √∫nicamente una lista separada por comas sin explicaciones adicionales.\"\n",
    "        )\n",
    "        try:\n",
    "            model = genai.GenerativeModel(self.text_model)\n",
    "            response = model.generate_content(prompt)\n",
    "            series_names = response.text if response and response.text else \"No se pudieron extraer los nombres.\"\n",
    "            logging.info(\"Nombres de series extra√≠dos correctamente.\")\n",
    "            self.cache[self.user_series][\"series_names\"] = series_names\n",
    "            return series_names\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error al extraer nombres de series: {e}\")\n",
    "            return \"Error al extraer nombres de series.\"\n",
    "\n",
    "    def generate_image_description(self, series_names: str) -> str:\n",
    "        prompt = (\n",
    "            f\"Genera una imagen representativa que combine elementos visuales de las siguientes series de televisi√≥n:\\n\"\n",
    "            f\"{series_names}\\n\"\n",
    "            \"La imagen debe reflejar los estilos y tem√°ticas de estas series.\"\n",
    "        )\n",
    "        try:\n",
    "            model = genai.GenerativeModel(self.vision_model)\n",
    "            response = model.generate_content(prompt)\n",
    "            image_description = response.text if response and response.text else \"No se pudo generar la descripci√≥n de la imagen.\"\n",
    "            logging.info(\"Descripci√≥n de imagen generada exitosamente.\")\n",
    "            self.cache[self.user_series][\"image_description\"] = image_description\n",
    "            return image_description\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error al generar descripci√≥n de imagen: {e}\")\n",
    "            return \"Error al generar descripci√≥n de imagen.\"\n",
    "\n",
    "    def display_results(self, recommendations: str, series_names: str, image_description: str):\n",
    "        print(\"\\n======== RESULTADOS ========\")\n",
    "        print(\"\\nüé¨ Recomendaciones de series similares:\\n\")\n",
    "        print(recommendations)\n",
    "        print(\"\\nüìú Series recomendadas (solo nombres):\\n\")\n",
    "        print(series_names)\n",
    "        print(\"\\nüñºÔ∏è Descripci√≥n de la imagen generada:\\n\")\n",
    "        print(image_description)\n",
    "        print(\"\\n============================\\n\")\n",
    "\n",
    "    def run(self):\n",
    "        self.user_series = self.get_user_series()\n",
    "\n",
    "        if self.user_series in self.cache:\n",
    "            print(f\"Ya existen resultados para '{self.user_series}'.\")\n",
    "            choice = input(\"¬øDesea actualizar los resultados? (s/n): \").strip().lower()\n",
    "            if choice != \"s\":\n",
    "                print(\"Usando resultados almacenados en cach√©.\")\n",
    "                cached = self.cache[self.user_series]\n",
    "                self.display_results(cached.get(\"recommendations\", \"No disponible\"),\n",
    "                                     cached.get(\"series_names\", \"No disponible\"),\n",
    "                                     cached.get(\"image_description\", \"No disponible\"))\n",
    "                return\n",
    "\n",
    "        recommendations = self.generate_recommendations(self.user_series)\n",
    "        series_names = self.extract_series_names(recommendations)\n",
    "        image_description = self.generate_image_description(series_names)\n",
    "        self.display_results(recommendations, series_names, image_description)\n",
    "        self.save_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e673883-5bc6-474b-9eb6-3d10aadee096",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_menu():\n",
    "    \"\"\"\n",
    "    Muestra un men√∫ interactivo para que el usuario pueda ingresar m√∫ltiples series y ver resultados.\n",
    "    \"\"\"\n",
    "    recommender = SeriesRecommender()\n",
    "    while True:\n",
    "        print(\"Men√∫ de Recomendaci√≥n de Series\")\n",
    "        print(\"1. Ingresar una nueva serie\")\n",
    "        print(\"2. Ver resultados para una serie ya ingresada\")\n",
    "        print(\"3. Salir\")\n",
    "        choice = input(\"Seleccione una opci√≥n (1/2/3): \").strip()\n",
    "        if choice == \"1\":\n",
    "            recommender.run()\n",
    "        elif choice == \"2\":\n",
    "            series = input(\"Ingrese el nombre de la serie: \").strip()\n",
    "            if series in recommender.cache:\n",
    "                cached = recommender.cache[series]\n",
    "                print(f\"\\nResultados para '{series}':\")\n",
    "                recommender.display_results(cached.get(\"recommendations\", \"No disponible\"),\n",
    "                                              cached.get(\"series_names\", \"No disponible\"),\n",
    "                                              cached.get(\"image_description\", \"No disponible\"))\n",
    "            else:\n",
    "                print(\"No se encontraron resultados para esa serie.\")\n",
    "        elif choice == \"3\":\n",
    "            print(\"Saliendo del programa.\")\n",
    "            break\n",
    "        else:\n",
    "            print(\"Opci√≥n no v√°lida. Intente nuevamente.\")\n",
    "        print(\"\\n------------------------------\\n\")\n",
    "        time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15fa162-fca7-4cd8-8008-3f2f408dfa35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-20 19:04:41,945 - INFO - Cach√© cargada desde archivo.\n",
      "2025-02-20 19:04:41,946 - INFO - API de Google Gemini configurada correctamente.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Men√∫ de Recomendaci√≥n de Series\n",
      "1. Ingresar una nueva serie\n",
      "2. Ver resultados para una serie ya ingresada\n",
      "3. Salir\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Seleccione una opci√≥n (1/2/3):  1\n",
      "Ingrese el nombre de su serie favorita:  Mr. Robot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-20 19:04:52,435 - INFO - Serie ingresada: Mr. Robot\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ya existen resultados para 'Mr. Robot'.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "¬øDesea actualizar los resultados? (s/n):  s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-20 19:04:57,654 - INFO - Recomendaciones obtenidas desde cach√©.\n",
      "2025-02-20 19:04:59,740 - INFO - Nombres de series extra√≠dos correctamente.\n",
      "2025-02-20 19:05:04,838 - INFO - Descripci√≥n de imagen generada exitosamente.\n",
      "2025-02-20 19:05:04,839 - INFO - Cach√© guardada en archivo JSON.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== RESULTADOS ========\n",
      "\n",
      "üé¨ Recomendaciones de series similares:\n",
      "\n",
      "**1. Utopia (Amazon Prime Video)**\n",
      "\n",
      "* Un grupo de personas descubre un manuscrito c√≥mico que predice calamidades futuras, lo que los lleva a una peligrosa conspiraci√≥n. Al igual que \"Mr. Robot\", \"Utopia\" explora temas de vigilancia, tecnolog√≠a y control social.\n",
      "\n",
      "**2. Devs (Hulu)**\n",
      "\n",
      "* Un ingeniero inform√°tico investiga la muerte de su novia y descubre un proyecto tecnol√≥gico secreto que manipula el tiempo. \"Devs\" comparte la atm√≥sfera inquietante, el ritmo tenso y las exploraciones existenciales de \"Mr. Robot\".\n",
      "\n",
      "**3. Twin Peaks (Showtime)**\n",
      "\n",
      "* La investigaci√≥n sobre el asesinato de una adolescente en un peque√±o pueblo revela un mundo sobrenatural y misterioso. Ambas series presentan una mezcla √∫nica de drama, suspenso y elementos surrealistas.\n",
      "\n",
      "**4. Severance (Apple TV+)**\n",
      "\n",
      "* Los empleados de una empresa se someten a un procedimiento para separar sus recuerdos del trabajo y la vida personal. Al igual que \"Mr. Robot\", \"Severance\" aborda temas de identidad, memoria y control corporativo.\n",
      "\n",
      "**5. Black Mirror (Netflix)**\n",
      "\n",
      "* Cada episodio de esta antolog√≠a dist√≥pica explora un futuro cercano tecnol√≥gicamente avanzado y sus posibles implicaciones sociales. Ambas series invitan a la reflexi√≥n sobre el impacto de la tecnolog√≠a en la sociedad y la naturaleza humana.\n",
      "\n",
      "üìú Series recomendadas (solo nombres):\n",
      "\n",
      "Utopia, Devs, Twin Peaks, Severance, Black Mirror\n",
      "\n",
      "üñºÔ∏è Descripci√≥n de la imagen generada:\n",
      "\n",
      "No puedo generar im√°genes. Soy un modelo de lenguaje grande, no un generador de im√°genes.  Sin embargo, puedo darte una descripci√≥n detallada de una imagen que combine los elementos visuales y tem√°ticos de esas series, para que puedas usarla como prompt para un generador de im√°genes como Midjourney, Dall-E 2 o Stable Diffusion:\n",
      "\n",
      "\n",
      "**Descripci√≥n de la imagen:**\n",
      "\n",
      "**Enfoque:** Un primer plano de un ojo humano, grande y detallado, con una pupila dilatada que refleja una escena fractal inquietantemente hermosa y compleja.  La pupila misma parece un microcosmos que contiene fragmentos de diferentes escenas.\n",
      "\n",
      "**Elementos:**\n",
      "\n",
      "* **Utopia:**  Un sutil dise√±o geom√©trico, casi invisible a primera vista, pero que se revela como un patr√≥n intrincado al inspeccionar m√°s de cerca el iris.  Puede incluir l√≠neas y formas que sugieren un complot secreto o una conspiraci√≥n.\n",
      "* **Devs:**  La escena fractal reflejada en la pupila debe ser altamente tecnol√≥gica y elegante, con referencias a circuitos, c√≥digo binario o estructuras de datos que se asemejan a la simulaci√≥n cu√°ntica de Devs.  Colores oscuros y met√°licos predominan.\n",
      "* **Twin Peaks:**  Una atm√≥sfera inquietante y surrealista rodea el ojo.  Se podr√≠a incluir una ligera distorsi√≥n de la imagen, como si fuera una fotograf√≠a vieja o una escena de un sue√±o.  El color podr√≠a ser apagado y ligeramente desaturado, con un toque de misterio.  Posible inclusi√≥n de un pino solitario y algo enigm√°tico a lo lejos en el reflejo.\n",
      "* **Severance:**  El ojo debe estar en una especie de limbo entre el mundo real y el de Lumon.  Se podr√≠an utilizar efectos de doble exposici√≥n para mostrar una oficina limpia y minimalista de Lumon superpuesta sobre una imagen m√°s ca√≥tica y distorsionada.\n",
      "* **Black Mirror:**  El reflejo en el ojo debe contener elementos tecnol√≥gicos y futuristas que transmitan un sentimiento de vigilancia, control y p√©rdida de privacidad.  Posible inclusi√≥n de una pantalla digital distorsionada, un c√≥digo binario parpadeante, o un ojo digital que observa.\n",
      "\n",
      "\n",
      "**Estilo:**  La imagen debe tener una est√©tica oscura, misteriosa y tecnol√≥gicamente avanzada.  La paleta de colores debe ser principalmente fr√≠a (azules, grises, negros), con acentos de colores m√°s vibrantes pero saturados en la escena fractal del reflejo.  La iluminaci√≥n debe ser tenue y dram√°tica, enfoc√°ndose en el ojo.  La textura debe ser detallada y compleja, sobre todo en la pupila.\n",
      "\n",
      "\n",
      "**Prompt para generador de im√°genes (ejemplo):**\n",
      "\n",
      "\"Close-up of a dilated human eye reflecting a complex fractal pattern.  Utopia-esque geometric design subtly embedded in the iris. Devs-style quantum simulation within the pupil. Twin Peaks-esque surreal atmosphere and slight distortion. Severance-inspired double exposure of a clean Lumon office and a chaotic landscape.  Black Mirror-esque technological surveillance elements in the reflection. Dark, mysterious, technologically advanced aesthetic. Cold color palette with vibrant accents in the fractal.  Detailed and complex texture.  8k resolution.  Artstation style.\"\n",
      "\n",
      "\n",
      "Recuerda ajustar este prompt a tu gusto y a las capacidades del generador de im√°genes que uses.  Experimentar con diferentes palabras clave y estilos te dar√° resultados m√°s interesantes.\n",
      "\n",
      "\n",
      "============================\n",
      "\n",
      "\n",
      "------------------------------\n",
      "\n",
      "Men√∫ de Recomendaci√≥n de Series\n",
      "1. Ingresar una nueva serie\n",
      "2. Ver resultados para una serie ya ingresada\n",
      "3. Salir\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Seleccione una opci√≥n (1/2/3):  2\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main_menu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67995c8a-e0c6-43f5-8287-e662814ae074",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
